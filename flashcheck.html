<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Nehme AI Labs - FlashCheck Benchmark">
    <title>FlashCheck | Nehme AI Labs</title>
    <script defer src="https://cloud.umami.is/script.js" data-website-id="f7f6d509-79ca-402a-bd51-d001df4e069f"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="blog.css"> <!-- Reusing some blog styles for consistency -->
    <link rel="stylesheet" href="flashcheck.css">
</head>
<body>
    <header class="main-header">
        <div class="container">
            <a href="index.html" class="logo">Nehme AI Labs</a>
            <nav class="main-nav">
                <a href="index.html">Home</a>
                <a href="flashcheck.html" class="active">FlashCheck</a>
                <a href="blog.html">Blog</a>
                <a href="index.html#contact">Contact</a>
            </nav>
        </div>
    </header>

    <main class="flashcheck-main">
        <div class="container">
            <div class="flashcheck-header">
                <h1 class="flashcheck-title">FlashCheck</h1>
                <p class="flashcheck-subtitle">The Anti-Hallucination Engine. Small, fast, and brutally accurate models that take a document and a claim, and respond only with "Yes" or "No".</p>
            </div>

            <div class="benchmark-section">
                <h2 class="benchmark-title">Performance & Efficiency</h2>
                <p class="benchmark-intro">FlashCheck models don't just lead in accuracy; they redefine efficiency. The chart below plots model size against average accuracy, demonstrating that our models deliver state-of-the-art performance in a fraction of the size.</p>
                <div class="chart-container">
                    <canvas id="performance-chart"></canvas>
                </div>
            </div>

            <div class="benchmark-section">
                <h2 class="benchmark-title">Dominance: A Clear Leader</h2>
                <p class="benchmark-intro">When ranked by pure accuracy, the Nehme-AI-FlashCheck-1B model establishes a new standard for performance, decisively outperforming all other models in the benchmark.</p>
                <div class="leaderboard-container">
                    <div class="leaderboard">
                        <div class="leaderboard-item rank-1">
                            <div class="leaderboard-rank">1</div>
                            <div class="leaderboard-model">Nehme-AI-FlashCheck-1B <span class="leaderboard-tag">Our Model</span></div>
                            <div class="leaderboard-score">81.9%</div>
                        </div>
                        <div class="leaderboard-item rank-2">
                            <div class="leaderboard-rank">2</div>
                            <div class="leaderboard-model">Bespoke-Minicheck-7B</div>
                            <div class="leaderboard-score">77.4%</div>
                        </div>
                        <div class="leaderboard-item rank-3">
                            <div class="leaderboard-rank">3</div>
                            <div class="leaderboard-model">Claude-3.5 Sonnet</div>
                            <div class="leaderboard-score">77.2%</div>
                        </div>
                        <div class="leaderboard-item">
                            <div class="leaderboard-rank">4</div>
                            <div class="leaderboard-model">Granite Guardian 3.3</div>
                            <div class="leaderboard-score">76.5%</div>
                        </div>
                        <div class="leaderboard-item">
                            <div class="leaderboard-rank">5</div>
                            <div class="leaderboard-model">Mistral-Large 2</div>
                            <div class="leaderboard-score">76.5%</div>
                        </div>
                        <div class="leaderboard-item">
                            <div class="leaderboard-rank">6</div>
                            <div class="leaderboard-model">gpt-4o-2024-05-13</div>
                            <div class="leaderboard-score">75.9%</div>
                        </div>
                        <div class="leaderboard-item">
                            <div class="leaderboard-rank">7</div>
                            <div class="leaderboard-model">FactCG-DeBERTa-L</div>
                            <div class="leaderboard-score">75.6%</div>
                        </div>
                        <div class="leaderboard-item">
                            <div class="leaderboard-rank">8</div>
                            <div class="leaderboard-model">Qwen2.5-72B-Instruct</div>
                            <div class="leaderboard-score">75.6%</div>
                        </div>
                        <div class="leaderboard-item rank-nehme">
                            <div class="leaderboard-rank">9</div>
                            <div class="leaderboard-model">Nehme-AI-FlashCheck-270M <span class="leaderboard-tag">Our Model</span></div>
                            <div class="leaderboard-score">75.5%</div>
                        </div>
                        <div class="leaderboard-item">
                            <div class="leaderboard-rank">10</div>
                            <div class="leaderboard-model">MiniCheck-Flan-T5-L</div>
                            <div class="leaderboard-score">75.0%</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="benchmark-section">
                <h2 class="benchmark-title">Full Benchmark Data</h2>
                <p class="benchmark-intro">The comprehensive results across all 11 datasets are detailed below.</p>
                
                <div class="sota-table-wrapper">
                    <table class="sota-table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Size</th>
                                <th>Average</th>
                                <th>CNN</th>
                                <th>XSum</th>
                                <th>MediaS</th>
                                <th>MeetB</th>
                                <th>WICE</th>
                                <th>REVEAL</th>
                                <th>ClaimV</th>
                                <th>FactCk</th>
                                <th>ExpertQA</th>
                                <th>LFQA</th>
                                <th>RAG Truth</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="nehme-model highlight">
                                <td>Nehme-AI-FlashCheck-1B</td>
                                <td>1B</td>
                                <td>81.9</td>
                                <td>90.0</td>
                                <td>71.1</td>
                                <td>78.7</td>
                                <td>84.2</td>
                                <td>56.7</td>
                                <td>87.8</td>
                                <td>77.3</td>
                                <td>76.1</td>
                                <td>73.5</td>
                                <td>82.9</td>
                                <td>84.6</td>
                            </tr>
                            <tr class="nehme-model highlight">
                                <td>Nehme-AI-FlashCheck-270M</td>
                                <td>270M</td>
                                <td>75.5</td>
                                <td>89.8</td>
                                <td>62.9</td>
                                <td>74.0</td>
                                <td>79.0</td>
                                <td>40.2</td>
                                <td>73.4</td>
                                <td>74.9</td>
                                <td>75.0</td>
                                <td>50.4</td>
                                <td>71.0</td>
                                <td>82.6</td>
                            </tr>
                            <tr>
                                <td>Bespoke-Minicheck-7B</td>
                                <td>7B</td>
                                <td>77.4</td>
                                <td>65.5</td>
                                <td>77.8</td>
                                <td>76.0</td>
                                <td>78.3</td>
                                <td>83.0</td>
                                <td>88.0</td>
                                <td>75.3</td>
                                <td>77.7</td>
                                <td>59.2</td>
                                <td>86.7</td>
                                <td>84.0</td>
                            </tr>
                            <tr>
                                <td>Claude-3.5 Sonnet</td>
                                <td>-</td>
                                <td>77.2</td>
                                <td>67.6</td>
                                <td>75.1</td>
                                <td>73.4</td>
                                <td>84.6</td>
                                <td>77.7</td>
                                <td>89.1</td>
                                <td>71.4</td>
                                <td>77.8</td>
                                <td>60.9</td>
                                <td>85.6</td>
                                <td>86.1</td>
                            </tr>
                            <tr>
                                <td>Granite Guardian 3.3</td>
                                <td>8B</td>
                                <td>76.5</td>
                                <td>67.0</td>
                                <td>74.9</td>
                                <td>74.0</td>
                                <td>78.6</td>
                                <td>76.6</td>
                                <td>89.6</td>
                                <td>75.9</td>
                                <td>76.1</td>
                                <td>59.6</td>
                                <td>86.9</td>
                                <td>82.2</td>
                            </tr>
                            <tr>
                                <td>Mistral-Large 2</td>
                                <td>123B</td>
                                <td>76.5</td>
                                <td>64.8</td>
                                <td>74.7</td>
                                <td>69.6</td>
                                <td>84.2</td>
                                <td>80.3</td>
                                <td>87.7</td>
                                <td>71.8</td>
                                <td>74.5</td>
                                <td>60.8</td>
                                <td>87.0</td>
                                <td>85.9</td>
                            </tr>
                            <tr>
                                <td>gpt-4o-2024-05-13</td>
                                <td>-</td>
                                <td>75.9</td>
                                <td>68.1</td>
                                <td>76.8</td>
                                <td>71.4</td>
                                <td>79.8</td>
                                <td>78.5</td>
                                <td>86.5</td>
                                <td>69.0</td>
                                <td>77.5</td>
                                <td>59.6</td>
                                <td>83.6</td>
                                <td>84.3</td>
                            </tr>
                            <tr>
                                <td>FactCG-DeBERTa-L</td>
                                <td>0.4B</td>
                                <td>75.6</td>
                                <td>70.1</td>
                                <td>73.9</td>
                                <td>72.3</td>
                                <td>74.3</td>
                                <td>74.2</td>
                                <td>88.4</td>
                                <td>78.5</td>
                                <td>72.1</td>
                                <td>59.1</td>
                                <td>86.7</td>
                                <td>82.3</td>
                            </tr>
                             <tr>
                                <td>Qwen2.5-72B-Instruct</td>
                                <td>72B</td>
                                <td>75.6</td>
                                <td>63.6</td>
                                <td>73.0</td>
                                <td>71.9</td>
                                <td>80.4</td>
                                <td>80.2</td>
                                <td>88.9</td>
                                <td>70.0</td>
                                <td>77.0</td>
                                <td>60.1</td>
                                <td>84.3</td>
                                <td>81.9</td>
                            </tr>
                            <tr>
                                <td>MiniCheck-Flan-T5-L</td>
                                <td>0.8B</td>
                                <td>75.0</td>
                                <td>69.9</td>
                                <td>74.3</td>
                                <td>73.6</td>
                                <td>77.3</td>
                                <td>72.2</td>
                                <td>86.2</td>
                                <td>74.6</td>
                                <td>74.7</td>
                                <td>59.0</td>
                                <td>85.2</td>
                                <td>78.0</td>
                            </tr>
                            <tr>
                                <td>Llama-3.3-70B-Instruct</td>
                                <td>70B</td>
                                <td>74.5</td>
                                <td>68.7</td>
                                <td>74.7</td>
                                <td>69.5</td>
                                <td>78.4</td>
                                <td>76.6</td>
                                <td>85.5</td>
                                <td>67.4</td>
                                <td>78.5</td>
                                <td>58.3</td>
                                <td>79.8</td>
                                <td>82.6</td>
                            </tr>
                            <tr>
                                <td>Llama-3.1-405B-Instruct</td>
                                <td>405B</td>
                                <td>74.4</td>
                                <td>64.8</td>
                                <td>75.1</td>
                                <td>68.6</td>
                                <td>81.2</td>
                                <td>71.8</td>
                                <td>86.4</td>
                                <td>67.5</td>
                                <td>79.4</td>
                                <td>58.5</td>
                                <td>81.9</td>
                                <td>82.9</td>
                            </tr>
                            <tr>
                                <td>QwQ-32B-Preview</td>
                                <td>32B</td>
                                <td>71.8</td>
                                <td>57.0</td>
                                <td>71.6</td>
                                <td>69.3</td>
                                <td>78.5</td>
                                <td>72.3</td>
                                <td>86.2</td>
                                <td>67.7</td>
                                <td>75.6</td>
                                <td>60.0</td>
                                <td>78.9</td>
                                <td>72.4</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div id="anti-hallucination" class="benchmark-section">
                <h2 class="benchmark-title">The Anti-Hallucination Engine</h2>
                <p class="benchmark-intro">Hallucinations in Large Language Models are not a bug; they are a feature of probabilistic generation. The solution is not to build ever-larger models, but to enforce rigor through external verification. FlashCheck is designed for this purpose.</p>
                <div class="solution-grid">
                    <div class="solution-item fade-in" data-delay="0">
                        <div class="solution-icon">01</div>
                        <h3 class="solution-headline">Generate, then Verify</h3>
                        <p class="solution-text">Integrate FlashCheck as the final step in your RAG (Retrieval-Augmented Generation) pipeline. After your primary LLM generates a response, FlashCheck verifies each generated claim against the source documents. If a claim returns "No", it's a hallucination. It's that simple.</p>
                    </div>
                    <div class="solution-item fade-in" data-delay="100">
                        <div class="solution-icon">02</div>
                        <h3 class="solution-headline">Lightweight & Fast</h3>
                        <p class="solution-text">Because FlashCheck models are small and specialized, they add minimal latency to your pipeline. You get the benefit of factual accuracy without a significant performance penalty, making it practical for real-time applications.</p>
                    </div>
                    <div class="solution-item fade-in" data-delay="200">
                        <div class="solution-icon">03</div>
                        <h3 class="solution-headline">Deterministic Trust</h3>
                        <p class="solution-text">The "Yes" or "No" output provides a deterministic, binary signal of trustworthiness. This allows you to programmatically filter, flag, or correct generated content, moving from a system of probabilistic trust to one of architectural certainty.</p>
                    </div>
                </div>
            </div>

            <div class="contact-section">
                <p>FlashCheck models are available for audit and deployment. If you are ready to replace your inefficient fact-verification pipeline with a surgical, cost-effective solution, we should talk.</p>
                <a href="index.html#contact" class="cta-button">
                    <span class="cta-text">Request an Audit</span>
                    <span class="cta-arrow">â†’</span>
                </a>
            </div>
        </div>
    </main>
    <script src="script.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="flashcheck-charts.js"></script>
</body>
</html>
